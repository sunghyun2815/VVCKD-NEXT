'use client';

import React, { useState, useEffect, useRef, useCallback } from 'react';
import type { 
  MusicRoom, 
  AudioFile, 
  ChatMessage, 
  User,
  AudioPlayerState,
  WaveformData 
} from '../types/project.types';
import styles from './MusicRoomView.module.css';

// ===== Props íƒ€ì… =====
interface MusicRoomViewProps {
  room: MusicRoom;
  currentUser: string;
  connectedUsers: User[];
  onLeaveRoom: () => void;
  socket?: any; // Socket.IO ì¸ìŠ¤í„´ìŠ¤
}

// ===== ë©”ì¸ ì»´í¬ë„ŒíŠ¸ =====
export default function MusicRoomView({
  room,
  currentUser,
  connectedUsers,
  onLeaveRoom,
  socket
}: MusicRoomViewProps) {
  // ===== ìƒíƒœ ê´€ë¦¬ =====
  const [currentTrack, setCurrentTrack] = useState<AudioFile | null>(null);
  const [playlist, setPlaylist] = useState<AudioFile[]>([]);
  const [audioPlayerState, setAudioPlayerState] = useState<AudioPlayerState>({
    isPlaying: false,
    currentTime: 0,
    duration: 0,
    volume: 0.8,
    isLoading: false,
    error: null
  });
  const [chatMessages, setChatMessages] = useState<ChatMessage[]>([]);
  const [waveformData, setWaveformData] = useState<WaveformData | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [showUploader, setShowUploader] = useState(false);
  const [showPlaylist, setShowPlaylist] = useState(true);
  const [showChat, setShowChat] = useState(true);

  // ===== Refs =====
  const audioRef = useRef<HTMLAudioElement>(null);
  const waveformRef = useRef<HTMLCanvasElement>(null);
  const chatContainerRef = useRef<HTMLDivElement>(null);

  // ===== ë”ë¯¸ ë°ì´í„° (ê°œë°œìš©) =====
  const dummyTracks: AudioFile[] = [
    {
      id: 'track-1',
      name: 'Chill Beats Vol.1.mp3',
      url: '/dummy-audio-1.mp3',
      blob: new Blob(),
      duration: 245,
      uploader: 'producer_alex',
      uploadedAt: '2024-01-15T10:30:00Z',
      size: 5242880,
      type: 'audio/mp3'
    },
    {
      id: 'track-2', 
      name: 'Study Session Loop.wav',
      url: '/dummy-audio-2.wav',
      blob: new Blob(),
      duration: 180,
      uploader: 'beat_master',
      uploadedAt: '2024-01-15T09:15:00Z',
      size: 12582912,
      type: 'audio/wav'
    },
    {
      id: 'track-3',
      name: 'Ambient Drone.mp3',
      url: '/dummy-audio-3.mp3',
      blob: new Blob(),
      duration: 320,
      uploader: currentUser,
      uploadedAt: '2024-01-15T11:45:00Z',
      size: 8388608,
      type: 'audio/mp3'
    }
  ];

  // ===== ì˜¤ë””ì˜¤ ì œì–´ í•¨ìˆ˜ë“¤ =====
  const handlePlay = useCallback(() => {
    if (!audioRef.current || !currentTrack) return;
    
    audioRef.current.play().then(() => {
      setAudioPlayerState(prev => ({ ...prev, isPlaying: true, error: null }));
      
      // Socket.IOë¡œ ì¬ìƒ ìƒíƒœ ë™ê¸°í™”
      if (socket) {
        socket.emit('sync_audio_playback', {
          roomId: room.id,
          time: audioRef.current!.currentTime,
          isPlaying: true
        });
      }
    }).catch(error => {
      console.error('âŒ Audio play error:', error);
      setAudioPlayerState(prev => ({ ...prev, error: 'ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' }));
    });
  }, [socket, room.id, currentTrack]);

  const handlePause = useCallback(() => {
    if (!audioRef.current) return;
    
    audioRef.current.pause();
    setAudioPlayerState(prev => ({ ...prev, isPlaying: false }));
    
    // Socket.IOë¡œ ì¼ì‹œì •ì§€ ìƒíƒœ ë™ê¸°í™”
    if (socket) {
      socket.emit('sync_audio_playback', {
        roomId: room.id,
        time: audioRef.current.currentTime,
        isPlaying: false
      });
    }
  }, [socket, room.id]);

  const handleSeek = useCallback((time: number) => {
    if (!audioRef.current) return;
    
    audioRef.current.currentTime = time;
    setAudioPlayerState(prev => ({ ...prev, currentTime: time }));
    
    // Socket.IOë¡œ ì‹œê°„ ë™ê¸°í™”
    if (socket) {
      socket.emit('sync_audio_playback', {
        roomId: room.id,
        time,
        isPlaying: audioPlayerState.isPlaying
      });
    }
  }, [socket, room.id, audioPlayerState.isPlaying]);

  const handleVolumeChange = useCallback((volume: number) => {
    if (audioRef.current) {
      audioRef.current.volume = volume;
    }
    setAudioPlayerState(prev => ({ ...prev, volume }));
  }, []);

  // ===== íŠ¸ë™ ê´€ë¦¬ í•¨ìˆ˜ë“¤ =====
  const handleTrackSelect = useCallback((track: AudioFile) => {
    console.log('ğŸµ Selecting track:', track.name);
    
    setAudioPlayerState(prev => ({ 
      ...prev, 
      isLoading: true, 
      error: null,
      currentTime: 0,
      isPlaying: false
    }));
    
    setCurrentTrack(track);
    
    // ì›¨ì´ë¸Œí¼ ë°ì´í„° ìƒì„± (ë”ë¯¸)
    setTimeout(() => {
      const dummyWaveform: WaveformData = {
        data: new Float32Array(Array.from({ length: 1000 }, () => Math.random() * 2 - 1)),
        step: 1,
        amp: 1,
        width: 1000,
        height: 100,
        isDummy: true
      };
      setWaveformData(dummyWaveform);
      setAudioPlayerState(prev => ({ ...prev, isLoading: false }));
    }, 1000);
  }, []);

  const handleNextTrack = useCallback(() => {
    if (playlist.length === 0) return;
    
    const currentIndex = playlist.findIndex(t => t.id === currentTrack?.id);
    const nextIndex = (currentIndex + 1) % playlist.length;
    handleTrackSelect(playlist[nextIndex]);
  }, [playlist, currentTrack, handleTrackSelect]);

  const handlePreviousTrack = useCallback(() => {
    if (playlist.length === 0) return;
    
    const currentIndex = playlist.findIndex(t => t.id === currentTrack?.id);
    const prevIndex = currentIndex === 0 ? playlist.length - 1 : currentIndex - 1;
    handleTrackSelect(playlist[prevIndex]);
  }, [playlist, currentTrack, handleTrackSelect]);

  // ===== ì±„íŒ… í•¨ìˆ˜ë“¤ =====
  const handleSendMessage = useCallback((message: string, timestamp?: number) => {
    const newMessage: ChatMessage = {
      id: `msg-${Date.now()}`,
      roomId: room.id,
      user: currentUser,
      message: message,
      timestamp: timestamp || audioPlayerState.currentTime,
      time: new Date().toISOString(),
      type: 'text'
    };

    setChatMessages(prev => [...prev, newMessage]);
    
    // Socket.IOë¡œ ë©”ì‹œì§€ ì „ì†¡
    if (socket) {
      socket.emit('music_chat_message', newMessage);
    }
  }, [room.id, currentUser, audioPlayerState.currentTime, socket]);

  const handleVoiceMessage = useCallback(async (audioBlob: Blob) => {
    console.log('ğŸ¤ Recording voice message:', audioBlob);
    
    const voiceMessage: ChatMessage = {
      id: `voice-${Date.now()}`,
      roomId: room.id,
      user: currentUser,
      message: '[Voice Message]',
      timestamp: audioPlayerState.currentTime,
      time: new Date().toISOString(),
      type: 'voice',
      audioUrl: URL.createObjectURL(audioBlob)
    };

    setChatMessages(prev => [...prev, voiceMessage]);
    
    if (socket) {
      socket.emit('music_voice_message', voiceMessage);
    }
  }, [room.id, currentUser, audioPlayerState.currentTime, socket]);

  // ===== íŒŒì¼ ì—…ë¡œë“œ í•¨ìˆ˜ë“¤ =====
  const handleFileUpload = useCallback(async (file: File) => {
    console.log('ğŸ“ Uploading file:', file.name);
    
    setShowUploader(false);
    
    const newTrack: AudioFile = {
      id: `track-${Date.now()}`,
      name: file.name,
      url: URL.createObjectURL(file),
      blob: file,
      duration: 0, // ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ë¶„ì„ í•„ìš”
      uploader: currentUser,
      uploadedAt: new Date().toISOString(),
      size: file.size,
      type: file.type
    };

    setPlaylist(prev => [...prev, newTrack]);
    
    // Socket.IOë¡œ íŒŒì¼ ì—…ë¡œë“œ
    if (socket) {
      socket.emit('upload_audio_file', {
        file: await file.arrayBuffer(),
        fileName: file.name,
        roomId: room.id
      });
    }
  }, [currentUser, room.id, socket]);

  // ===== ì›¨ì´ë¸Œí¼ ê·¸ë¦¬ê¸° =====
  const drawWaveform = useCallback(() => {
    if (!waveformRef.current || !waveformData) return;
    
    const canvas = waveformRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const { width, height } = canvas;
    const { data } = waveformData;
    
    // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
    ctx.clearRect(0, 0, width, height);
    ctx.fillStyle = '#000';
    ctx.fillRect(0, 0, width, height);
    
    // ì›¨ì´ë¸Œí¼ ê·¸ë¦¬ê¸°
    ctx.strokeStyle = '#FF5500';
    ctx.lineWidth = 1;
    ctx.beginPath();
    
    const step = data.length / width;
    
    for (let x = 0; x < width; x++) {
      const index = Math.floor(x * step);
      const amplitude = data[index] || 0;
      const y = (height / 2) + (amplitude * height / 4);
      
      if (x === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    }
    
    ctx.stroke();
    
    // ì¬ìƒ ìœ„ì¹˜ í‘œì‹œ
    if (audioPlayerState.duration > 0) {
      const progress = audioPlayerState.currentTime / audioPlayerState.duration;
      const progressX = progress * width;
      
      ctx.strokeStyle = '#00FF00';
      ctx.lineWidth = 2;
      ctx.beginPath();
      ctx.moveTo(progressX, 0);
      ctx.lineTo(progressX, height);
      ctx.stroke();
    }
    
    // ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    chatMessages.forEach(msg => {
      if (msg.timestamp && audioPlayerState.duration > 0) {
        const msgProgress = msg.timestamp / audioPlayerState.duration;
        const msgX = msgProgress * width;
        
        ctx.fillStyle = msg.type === 'voice' ? '#FFAA00' : '#FF5500';
        ctx.fillRect(msgX - 1, height - 10, 2, 10);
      }
    });
    
  }, [waveformData, audioPlayerState, chatMessages]);

  // ===== íš¨ê³¼ë“¤ =====
  
  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ë”ë¯¸ ë°ì´í„° ë¡œë“œ
  useEffect(() => {
    setPlaylist(dummyTracks);
    if (dummyTracks.length > 0) {
      handleTrackSelect(dummyTracks[0]);
    }
    
    // ë”ë¯¸ ì±„íŒ… ë©”ì‹œì§€
    const dummyMessages: ChatMessage[] = [
      {
        id: 'msg-1',
        roomId: room.id,
        user: 'producer_alex',
        message: 'ìƒˆë¡œìš´ ë¹„íŠ¸ ì—…ë¡œë“œí–ˆì–´ìš”! í™•ì¸í•´ë³´ì„¸ìš”',
        timestamp: 30,
        time: new Date(Date.now() - 300000).toISOString(),
        type: 'text'
      },
      {
        id: 'msg-2',
        roomId: room.id,
        user: 'beat_master',
        message: 'ì´ ë¶€ë¶„ ë² ì´ìŠ¤ ë¼ì¸ì´ ë„ˆë¬´ ì¢‹ë„¤ìš” ğŸ”¥',
        timestamp: 120,
        time: new Date(Date.now() - 180000).toISOString(),
        type: 'text'
      }
    ];
    
    setChatMessages(dummyMessages);
  }, [room.id, handleTrackSelect]);

  // ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const handleTimeUpdate = () => {
      setAudioPlayerState(prev => ({
        ...prev,
        currentTime: audio.currentTime
      }));
    };

    const handleLoadedMetadata = () => {
      setAudioPlayerState(prev => ({
        ...prev,
        duration: audio.duration
      }));
    };

    const handleEnded = () => {
      setAudioPlayerState(prev => ({ ...prev, isPlaying: false }));
      handleNextTrack();
    };

    const handleError = () => {
      setAudioPlayerState(prev => ({ 
        ...prev, 
        isPlaying: false,
        error: 'ì˜¤ë””ì˜¤ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' 
      }));
    };

    audio.addEventListener('timeupdate', handleTimeUpdate);
    audio.addEventListener('loadedmetadata', handleLoadedMetadata);
    audio.addEventListener('ended', handleEnded);
    audio.addEventListener('error', handleError);

    return () => {
      audio.removeEventListener('timeupdate', handleTimeUpdate);
      audio.removeEventListener('loadedmetadata', handleLoadedMetadata);
      audio.removeEventListener('ended', handleEnded);
      audio.removeEventListener('error', handleError);
    };
  }, [handleNextTrack]);

  // ì›¨ì´ë¸Œí¼ ë‹¤ì‹œ ê·¸ë¦¬ê¸°
  useEffect(() => {
    drawWaveform();
  }, [drawWaveform]);

  // Socket.IO ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
  useEffect(() => {
    if (!socket) return;

    const handleAudioSync = ({ time, isPlaying }: { time: number; isPlaying: boolean }) => {
      if (!audioRef.current) return;
      
      audioRef.current.currentTime = time;
      if (isPlaying) {
        audioRef.current.play();
      } else {
        audioRef.current.pause();
      }
      
      setAudioPlayerState(prev => ({
        ...prev,
        currentTime: time,
        isPlaying
      }));
    };

    const handleChatMessage = (message: ChatMessage) => {
      setChatMessages(prev => [...prev, message]);
    };

    const handleAudioFileUploaded = (file: AudioFile) => {
      setPlaylist(prev => [...prev, file]);
    };

    socket.on('audio_playback_sync', handleAudioSync);
    socket.on('music_chat_message', handleChatMessage);
    socket.on('music_voice_message', handleChatMessage);
    socket.on('audio_file_uploaded', handleAudioFileUploaded);

    return () => {
      socket.off('audio_playback_sync', handleAudioSync);
      socket.off('music_chat_message', handleChatMessage);
      socket.off('music_voice_message', handleChatMessage);
      socket.off('audio_file_uploaded', handleAudioFileUploaded);
    };
  }, [socket]);

  // ì±„íŒ… ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
    }
  }, [chatMessages]);

  // í¬ë§·íŒ… í•¨ìˆ˜ë“¤
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const formatFileSize = (bytes: number): string => {
    const mb = bytes / (1024 * 1024);
    return `${mb.toFixed(1)}MB`;
  };

  // ===== ë Œë”ë§ =====
  return (
    <div className={styles.musicRoomContainer}>
      {/* ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ */}
      <audio
        ref={audioRef}
        src={currentTrack?.url}
        preload="metadata"
        style={{ display: 'none' }}
      />

      {/* ìƒë‹¨ í—¤ë” */}
      <header className={styles.roomHeader}>
        <div className={styles.roomInfo}>
          <h1 className={styles.roomTitle}>{room.name}</h1>
          <div className={styles.roomMeta}>
            <span className={styles.userCount}>
              ğŸ‘¥ {connectedUsers.length}/{room.maxUsers}
            </span>
            <span className={styles.trackCount}>
              ğŸµ {playlist.length} tracks
            </span>
            <span className={styles.roomStatus}>
              ğŸ”´ LIVE
            </span>
          </div>
        </div>
        
        <div className={styles.roomControls}>
          <button
            onClick={() => setShowUploader(true)}
            className={styles.uploadBtn}
            disabled={!socket}
          >
            ğŸ“ UPLOAD
          </button>
          <button
            onClick={onLeaveRoom}
            className={styles.leaveBtn}
          >
            â† LEAVE
          </button>
        </div>
      </header>

      {/* ë©”ì¸ ì½˜í…ì¸  */}
      <main className={styles.mainContent}>
        {/* ì™¼ìª½: ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ & ì›¨ì´ë¸Œí¼ */}
        <section className={styles.audioSection}>
          {/* í˜„ì¬ íŠ¸ë™ ì •ë³´ */}
          <div className={styles.trackInfo}>
            {currentTrack ? (
              <>
                <div className={styles.trackArtwork}>
                  ğŸµ
                </div>
                <div className={styles.trackDetails}>
                  <h3 className={styles.trackTitle}>{currentTrack.name}</h3>
                  <p className={styles.trackUploader}>by {currentTrack.uploader}</p>
                  <p className={styles.trackMeta}>
                    {formatTime(audioPlayerState.duration)} â€¢ {formatFileSize(currentTrack.size)}
                  </p>
                </div>
              </>
            ) : (
              <div className={styles.noTrack}>
                <p>íŠ¸ë™ì„ ì„ íƒí•´ì£¼ì„¸ìš”</p>
              </div>
            )}
            
            {audioPlayerState.isLoading && (
              <div className={styles.loadingIndicator}>
                <div className={styles.spinner}></div>
                <span>Loading...</span>
              </div>
            )}
          </div>

          {/* ì˜¤ë””ì˜¤ ì»¨íŠ¸ë¡¤ */}
          <div className={styles.audioControls}>
            <button
              onClick={handlePreviousTrack}
              disabled={!currentTrack || playlist.length <= 1}
              className={styles.controlBtn}
            >
              â®
            </button>
            
            <button
              onClick={audioPlayerState.isPlaying ? handlePause : handlePlay}
              disabled={!currentTrack || audioPlayerState.isLoading}
              className={`${styles.playBtn} ${audioPlayerState.isPlaying ? styles.playing : ''}`}
            >
              {audioPlayerState.isPlaying ? 'â¸' : 'â–¶'}
            </button>
            
            <button
              onClick={handleNextTrack}
              disabled={!currentTrack || playlist.length <= 1}
              className={styles.controlBtn}
            >
              â­
            </button>
            
            <div className={styles.timeDisplay}>
              <span>{formatTime(audioPlayerState.currentTime)}</span>
              <span>/</span>
              <span>{formatTime(audioPlayerState.duration)}</span>
            </div>
            
            <div className={styles.volumeControl}>
              <span>ğŸ”Š</span>
              <input
                type="range"
                min="0"
                max="1"
                step="0.01"
                value={audioPlayerState.volume}
                onChange={(e) => handleVolumeChange(parseFloat(e.target.value))}
                className={styles.volumeSlider}
              />
            </div>
          </div>

          {/* ì›¨ì´ë¸Œí¼ */}
          <div className={styles.waveformContainer}>
            <canvas
              ref={waveformRef}
              width={800}
              height={200}
              className={styles.waveformCanvas}
              onClick={(e) => {
                if (!audioPlayerState.duration) return;
                const rect = e.currentTarget.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const progress = x / rect.width;
                const time = progress * audioPlayerState.duration;
                handleSeek(time);
              }}
            />
            
            {audioPlayerState.error && (
              <div className={styles.errorMessage}>
                âŒ {audioPlayerState.error}
              </div>
            )}
          </div>
        </section>

        {/* ì˜¤ë¥¸ìª½: ì±„íŒ… & í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ */}
        <aside className={styles.sidePanel}>
          {/* ì‚¬ì´ë“œ íŒ¨ë„ íƒ­ */}
          <div className={styles.sidePanelTabs}>
            <button
              onClick={() => setShowChat(true)}
              className={`${styles.tabBtn} ${showChat ? styles.active : ''}`}
            >
              ğŸ’¬ CHAT ({chatMessages.length})
            </button>
            <button
              onClick={() => setShowChat(false)}
              className={`${styles.tabBtn} ${!showChat ? styles.active : ''}`}
            >
              ğŸµ PLAYLIST ({playlist.length})
            </button>
          </div>

          {/* ì±„íŒ… ì„¹ì…˜ */}
          {showChat && (
            <div className={styles.chatSection}>
              <div className={styles.connectedUsers}>
                <h4>ì—°ê²°ëœ ì‚¬ìš©ì ({connectedUsers.length}ëª…)</h4>
                <div className={styles.userList}>
                  {connectedUsers.map(user => (
                    <span 
                      key={user.id} 
                      className={`${styles.userTag} ${user.username === currentUser ? styles.currentUser : ''}`}
                    >
                      {user.username}
                      {user.role === 'admin' && ' ğŸ‘‘'}
                    </span>
                  ))}
                </div>
              </div>

              <div 
                ref={chatContainerRef}
                className={styles.chatMessages}
              >
                {chatMessages.map(msg => (
                  <div 
                    key={msg.id} 
                    className={`${styles.chatMessage} ${msg.user === currentUser ? styles.ownMessage : ''}`}
                  >
                    <div className={styles.messageHeader}>
                      <strong className={styles.messageUser}>
                        {msg.user}
                        {msg.user === currentUser && ' (ë‚˜)'}
                      </strong>
                      <span className={styles.messageTime}>
                        {new Date(msg.time).toLocaleTimeString()}
                      </span>
                      {msg.timestamp > 0 && (
                        <button
                          onClick={() => handleSeek(msg.timestamp)}
                          className={styles.timestampBtn}
                        >
                          @{formatTime(msg.timestamp)}
                        </button>
                      )}
                    </div>
                    <div className={styles.messageContent}>
                      {msg.type === 'voice' ? (
                        <div className={styles.voiceMessage}>
                          ğŸ¤ ìŒì„± ë©”ì‹œì§€
                          {msg.audioUrl && (
                            <audio controls src={msg.audioUrl} />
                          )}
                        </div>
                      ) : (
                        msg.message
                      )}
                    </div>
                  </div>
                ))}
              </div>

              <div className={styles.chatInput}>
                <MessageInput 
                  onSendMessage={handleSendMessage}
                  onVoiceMessage={handleVoiceMessage}
                  isRecording={isRecording}
                  onRecordingChange={setIsRecording}
                  currentTime={audioPlayerState.currentTime}
                />
              </div>
            </div>
          )}

          {/* í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì„¹ì…˜ */}
          {!showChat && (
            <div className={styles.playlistSection}>
              <div className={styles.playlistHeader}>
                <h4>í”Œë ˆì´ë¦¬ìŠ¤íŠ¸</h4>
                <span className={styles.playlistCount}>{playlist.length}ê°œ íŠ¸ë™</span>
              </div>
              
              <div className={styles.playlistTracks}>
                {playlist.map((track, index) => (
                  <div
                    key={track.id}
                    className={`${styles.trackItem} ${
                      currentTrack?.id === track.id ? styles.activeTrack : ''
                    }`}
                    onClick={() => handleTrackSelect(track)}
                  >
                    <div className={styles.trackNumber}>
                      {currentTrack?.id === track.id ? 'â–¶' : index + 1}
                    </div>
                    <div className={styles.trackDetails}>
                      <div className={styles.trackName}>{track.name}</div>
                      <div className={styles.trackInfo}>
                        by {track.uploader} â€¢ {formatFileSize(track.size)}
                      </div>
                    </div>
                    <div className={styles.trackDuration}>
                      {formatTime(track.duration)}
                    </div>
                  </div>
                ))}
              </div>
            </div>
          )}
        </aside>
      </main>

      {/* íŒŒì¼ ì—…ë¡œë“œ ëª¨ë‹¬ */}
      {showUploader && (
        <FileUploadModal
          onFileUpload={handleFileUpload}
          onClose={() => setShowUploader(false)}
        />
      )}
    </div>
  );
}

// ===== í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ë“¤ =====

// ë©”ì‹œì§€ ì…ë ¥ ì»´í¬ë„ŒíŠ¸
interface MessageInputProps {
  onSendMessage: (message: string, timestamp?: number) => void;
  onVoiceMessage: (audioBlob: Blob) => void;
  isRecording: boolean;
  onRecordingChange: (recording: boolean) => void;
  currentTime: number;
}

function MessageInput({ 
  onSendMessage, 
  onVoiceMessage, 
  isRecording, 
  onRecordingChange,
  currentTime 
}: MessageInputProps) {
  const [message, setMessage] = useState('');
  const [withTimestamp, setWithTimestamp] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);

  const handleSend = () => {
    if (message.trim()) {
      onSendMessage(message.trim(), withTimestamp ? currentTime : undefined);
      setMessage('');
      setWithTimestamp(false);
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      
      mediaRecorderRef.current = mediaRecorder;
      recordedChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(recordedChunksRef.current, { type: 'audio/webm' });
        onVoiceMessage(audioBlob);
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.start();
      onRecordingChange(true);
    } catch (error) {
      console.error('âŒ Failed to start recording:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      onRecordingChange(false);
    }
  };

  return (
    <div className={styles.messageInput}>
      <div className={styles.inputRow}>
        <input
          type="text"
          value={message}
          onChange={(e) => setMessage(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && handleSend()}
          placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
          className={styles.textInput}
          disabled={isRecording}
        />
        
        <button
          onClick={isRecording ? stopRecording : startRecording}
          className={`${styles.voiceBtn} ${isRecording ? styles.recording : ''}`}
        >
          {isRecording ? 'â¹' : 'ğŸ¤'}
        </button>
        
        <button
          onClick={handleSend}
          disabled={!message.trim() || isRecording}
          className={styles.sendBtn}
        >
          ğŸ“¤
        </button>
      </div>
      
      <div className={styles.inputOptions}>
        <label className={styles.timestampOption}>
          <input
            type="checkbox"
            checked={withTimestamp}
            onChange={(e) => setWithTimestamp(e.target.checked)}
          />
          í˜„ì¬ ì¬ìƒ ìœ„ì¹˜ì— ëŒ“ê¸€ ë‹¬ê¸° ({Math.floor(currentTime)}ì´ˆ)
        </label>
      </div>
      
      {isRecording && (
        <div className={styles.recordingIndicator}>
          ğŸ”´ ë…¹ìŒ ì¤‘... ë‹¤ì‹œ í´ë¦­í•´ì„œ ì™„ë£Œ
        </div>
      )}
    </div>
  );
}

// íŒŒì¼ ì—…ë¡œë“œ ëª¨ë‹¬
interface FileUploadModalProps {
  onFileUpload: (file: File) => void;
  onClose: () => void;
}

function FileUploadModal({ onFileUpload, onClose }: FileUploadModalProps) {
  const [dragOver, setDragOver] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    setDragOver(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    setDragOver(false);
  };

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault();
    setDragOver(false);
    
    const files = Array.from(e.dataTransfer.files);
    const audioFile = files.find(file => file.type.startsWith('audio/'));
    
    if (audioFile) {
      onFileUpload(audioFile);
    } else {
      alert('ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.');
    }
  };

  const handleFileSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      onFileUpload(file);
    }
  };

  return (
    <div className={styles.modalOverlay} onClick={onClose}>
      <div 
        className={styles.uploadModal}
        onClick={(e) => e.stopPropagation()}
      >
        <div className={styles.modalHeader}>
          <h3>ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ</h3>
          <button onClick={onClose} className={styles.closeBtn}>âœ•</button>
        </div>
        
        <div 
          className={`${styles.dropZone} ${dragOver ? styles.dragOver : ''}`}
          onDragOver={handleDragOver}
          onDragLeave={handleDragLeave}
          onDrop={handleDrop}
          onClick={() => fileInputRef.current?.click()}
        >
          <div className={styles.dropZoneContent}>
            <div className={styles.uploadIcon}>ğŸ“</div>
            <p>íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•´ì„œ ì„ íƒí•˜ì„¸ìš”</p>
            <p className={styles.supportedFormats}>
              ì§€ì› í˜•ì‹: MP3, WAV, OGG, WEBM, AAC (ìµœëŒ€ 50MB)
            </p>
          </div>
        </div>
        
        <input
          ref={fileInputRef}
          type="file"
          accept="audio/*"
          onChange={handleFileSelect}
          style={{ display: 'none' }}
        />
        
        <div className={styles.modalFooter}>
          <p className={styles.uploadNote}>
            âš ï¸ ì—…ë¡œë“œëœ íŒŒì¼ì€ ë£¸ì˜ ëª¨ë“  ì‚¬ìš©ìì™€ ê³µìœ ë©ë‹ˆë‹¤
          </p>
        </div>
      </div>
    </div>
  );
}